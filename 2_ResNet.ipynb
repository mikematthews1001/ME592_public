{"cells":[{"cell_type":"markdown","metadata":{"id":"4zsDWUk5cavn"},"source":["# Deep Learning for Image Classification\n","\n","Welcome to deep learning for image classification tutorial!\n","**In this notebook, you will**:\n","- Learn the basics of PyTorch, a powerful but easy to use package for scientific computing (and deep learning)\n","- Learn how to build and train a convolutional neural network for image classification.\n","\n","If you have never used jupyter notebooks, nor Colab notebooks, [here](https://colab.research.google.com/notebooks/welcome.ipynb) is a short intro.\n","\n","\n","## I. PyTorch Tutorial\n","\n","We will briefly go through the basics of the PyTorch package, playing with toy examples.\n","\n","If you know already how to use PyTorch, then you can directly go to the second part of this tutorial\n","\n","## II. Training a classifier\n","\n","In this part, we will train a Convolutional Neural Network to classify images of 10 different classes (dogs, cats, car, ...) and see how our model performs on the test set.  \n","\n","\n","## III. Exploring CNN Architectures\n","\n","This is the part where you get your hands dirty ;). Your mission is to experiment different CNN architectures and set hyperparameters in order to obtain the best accuracy on the test set!\n"]},{"cell_type":"markdown","metadata":{"id":"JgRltjas9PpN"},"source":["The following command sets the backend of matplotlib to the 'inline' backend so that the output of plotting commands is displayed inline within frontends like the Jupyter notebook, directly below the code cell that produced it:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3168,"status":"ok","timestamp":1675194778290,"user":{"displayName":"Aditya Balu","userId":"00240964590008989444"},"user_tz":360},"id":"GkjN23FKt2D-","outputId":"eac69f90-47dc-41b7-f540-572ecd4f4666"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'PDL'...\n","remote: Enumerating objects: 47, done.\u001b[K\n","remote: Total 47 (delta 0), reused 0 (delta 0), pack-reused 47\u001b[K\n","Unpacking objects: 100% (47/47), 5.44 MiB | 3.33 MiB/s, done.\n"]}],"source":["%matplotlib inline\n","!git clone https://github.com/adityabalu/PDL.git\n","!cp PDL/DataProcessors/mnist.py fmnist.py"]},{"cell_type":"markdown","metadata":{"id":"YAz-fhRRdFaR"},"source":["### Plotting functions and useful imports\n","\n","You can skip this part"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nnee2WPudA9K"},"outputs":[],"source":["# Python 2/3 compatibility\n","from __future__ import print_function, division\n","\n","import itertools\n","import time\n","\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Colors from Colorbrewer Paired_12\n","colors = [[31, 120, 180], [51, 160, 44]]\n","colors = [(r / 255, g / 255, b / 255) for (r, g, b) in colors]\n","\n","# functions to show an image\n","def imshow(img):\n","    \"\"\"\n","    :param img: (PyTorch Tensor)\n","    \"\"\"\n","    # unnormalize\n","    img = img / 2 + 0.5     \n","    # Convert tensor to numpy array\n","    npimg = img.numpy()\n","    # Color channel first -\u003e color channel last\n","    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n","\n","\n","\n","def plot_losses(train_history, val_history):\n","    x = np.arange(1, len(train_history) + 1)\n","\n","    plt.figure(figsize=(8, 6))\n","    plt.plot(x, train_history, color=colors[0], label=\"Training loss\", linewidth=2)\n","    plt.plot(x, val_history, color=colors[1], label=\"Validation loss\", linewidth=2)\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend(loc='upper right')\n","    plt.title(\"Evolution of the training and validation loss\")\n","    plt.show()\n","\n","def plot_confusion_matrix(cm, classes,\n","                          normalize=False,\n","                          title='Confusion matrix',\n","                          cmap=plt.cm.Blues):\n","    \"\"\"\n","    This function prints and plots the confusion matrix.\n","    Normalization can be applied by setting `normalize=True`.\n","    from http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n","    :param cm: (numpy matrix) confusion matrix\n","    :param classes: [str]\n","    :param normalize: (bool)\n","    :param title: (str)\n","    :param cmap: (matplotlib color map)\n","    \"\"\"\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","        \n","    plt.figure(figsize=(8, 8))   \n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes, rotation=45)\n","    plt.yticks(tick_marks, classes)\n","\n","    fmt = '.2f' if normalize else 'd'\n","    thresh = cm.max() / 2.\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        plt.text(j, i, format(cm[i, j], fmt),\n","                 horizontalalignment=\"center\",\n","                 color=\"white\" if cm[i, j] \u003e thresh else \"black\")\n","\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oIONy65XZTrC"},"outputs":[],"source":["import numpy as np\n","import torch"]},{"cell_type":"markdown","metadata":{"id":"iX2ltR_zcayA"},"source":["Seed the random generator to have reproducible results:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"335xvR6acayB"},"outputs":[],"source":["seed = 42\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","\n","if torch.cuda.is_available():\n","  # Make CuDNN Determinist\n","  torch.backends.cudnn.deterministic = True\n","  torch.cuda.manual_seed(seed)\n","\n","# Define default device, we should use the GPU (cuda) if available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"]},{"cell_type":"markdown","metadata":{"id":"UWTdj2uYcax7"},"source":["### 1. Loading Custom Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KRrvrIi0t2Em"},"outputs":[],"source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms"]},{"cell_type":"markdown","metadata":{"id":"TO6VxImEtNB0"},"source":["# Define the data loader"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1675194785419,"user":{"displayName":"Aditya Balu","userId":"00240964590008989444"},"user_tz":360},"id":"EiSvXmNztlek","outputId":"d114f989-e72a-4fc6-cc26-4f7a8094a142"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u003c\u003e:6: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n","\u003c\u003e:8: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n","\u003c\u003e:11: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n","\u003c\u003e:6: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n","\u003c\u003e:8: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n","\u003c\u003e:11: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n","\u003cipython-input-6-18d3f400bbfa\u003e:6: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n","  if mode is 'train':\n","\u003cipython-input-6-18d3f400bbfa\u003e:8: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n","  elif mode is 'test':\n","\u003cipython-input-6-18d3f400bbfa\u003e:11: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n","  if mode is 'train':\n"]}],"source":["from fmnist import train_images, test_images, train_labels, test_labels\n","\n","class FMNIST(torch.utils.data.Dataset):\n","    \"\"\"docstring for Fashion MNIST dataset\"\"\"\n","    def __init__(self, mode='train', transform=None):\n","        if mode is 'train':\n","            self.data, self.labels = train_images(), train_labels()\n","        elif mode is 'test':\n","            self.data, self.labels = test_images(), test_labels()\n","        self.indexes =  np.arange(self.data.shape[0])\n","        if mode is 'train':\n","            np.random.shuffle(self.indexes)\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return self.data.shape[0]\n","\n","    def __getitem__(self, index):\n","        img = self.data[self.indexes[index]]\n","        label = self.labels[self.indexes[index]]\n","        if self.transform is not None:\n","            img = self.transform(img)\n","        label = label.astype('int')\n","        return img, label\n","\n","from torch.utils.data.sampler import SubsetRandomSampler\n","\n","n_training_samples = 50000 # Max: 60 000 - n_val_samples\n","n_val_samples = 10000\n","n_test_samples = 10000\n","\n","train_sampler = SubsetRandomSampler(np.arange(n_training_samples, dtype=np.int64))\n","val_sampler = SubsetRandomSampler(np.arange(n_training_samples, n_training_samples + n_val_samples, dtype=np.int64))\n","test_sampler = SubsetRandomSampler(np.arange(n_test_samples, dtype=np.int64))\n","# (In the last case, indexes do not need to account for training ones because the train=False parameter in datasets.CIFAR will select from the test set)"]},{"cell_type":"markdown","metadata":{"id":"evFXNmbst2Ez"},"source":["The output of torchvision datasets are PILImage images of range [0, 1].\n","We transform them to Tensors of normalized range [-1, 1]\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZJ-hYN00t2E2"},"outputs":[],"source":["num_workers = 1\n","test_batch_size = 4\n","\n","transform = transforms.Compose(\n","    [   transforms.ToPILImage(),\n","        transforms.RandomCrop(28, padding=4),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.1307,), (0.3081,)),\n","    ])\n","\n","train_set = FMNIST(mode='train', transform=transform)\n","train_loader = torch.utils.data.DataLoader(train_set, batch_size=test_batch_size, sampler=train_sampler,\n","                                          num_workers=num_workers)\n","\n","test_set = FMNIST(mode='test', transform=transform)\n","\n","test_loader = torch.utils.data.DataLoader(test_set, batch_size=test_batch_size, sampler=test_sampler,\n","                                         num_workers=num_workers)\n","\n","classes = ('T-shirt/top', 'Trouser', 'Pullover', \n","           'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker',\n","           'Bag', 'Ankle boot')"]},{"cell_type":"markdown","metadata":{"id":"8ULHEu5Zt2Fa"},"source":["### 2. Define a Convolution Neural Network\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6k6rJyTTcayi"},"outputs":[],"source":["# Useful imports\n","import torch.nn as nn\n","import torch.nn.functional as F"]},{"cell_type":"markdown","metadata":{"id":"2SQi9Xf-t2Fu"},"source":["### 3. Define a loss function and optimizer\n","\n","Let's use a Classification Cross-Entropy loss and ADAM (optionally, SGD with momentum). You can read more about  [optimization methods](https://pytorch.org/docs/stable/optim.html).\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DOUiPtZQt2Fx"},"outputs":[],"source":["import torch.optim as optim\n","\n","def createLossAndOptimizer(net, learning_rate=0.001):\n","    # it combines softmax with negative log likelihood loss\n","    criterion = nn.CrossEntropyLoss()  \n","    #optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n","    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n","    return criterion, optimizer"]},{"cell_type":"markdown","metadata":{"id":"saJW5bKRt2F9"},"source":["### 4. Train the network\n","\n","\n","This is when things start to get interesting.\n","We simply have to loop over our data iterator, feed the inputs to the network, and optimize\n","\n"]},{"cell_type":"markdown","metadata":{"id":"mNf1e8QZcay1"},"source":["#### Data loader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EqDD8_z8cay2"},"outputs":[],"source":["def get_train_loader(batch_size):\n","    return torch.utils.data.DataLoader(train_set, batch_size=batch_size, sampler=train_sampler,\n","                                              num_workers=num_workers)\n","\n","# Use larger batch size for validation to speed up computation\n","val_loader = torch.utils.data.DataLoader(train_set, batch_size=128, sampler=val_sampler,\n","                                          num_workers=num_workers)"]},{"cell_type":"markdown","metadata":{"id":"yTDHHbLpcay5"},"source":["#### Training loop\n","The training script: it takes ~10s per epoch with batch_size = 32"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dATbDR5pt2GE"},"outputs":[],"source":["def train(net, batch_size, n_epochs, learning_rate):\n","    \"\"\"\n","    Train a neural network and print statistics of the training\n","    \n","    :param net: (PyTorch Neural Network)\n","    :param batch_size: (int)\n","    :param n_epochs: (int)  Number of iterations on the training set\n","    :param learning_rate: (float) learning rate used by the optimizer\n","    \"\"\"\n","    print(\"===== HYPERPARAMETERS =====\")\n","    print(\"batch_size=\", batch_size)\n","    print(\"n_epochs=\", n_epochs)\n","    print(\"learning_rate=\", learning_rate)\n","    print(\"=\" * 30)\n","    \n","    train_loader = get_train_loader(batch_size)\n","    n_minibatches = len(train_loader)\n","\n","    criterion, optimizer = createLossAndOptimizer(net, learning_rate)\n","    # Init variables used for plotting the loss\n","    train_history = []\n","    val_history = []\n","\n","    training_start_time = time.time()\n","    best_error = np.inf\n","    best_model_path = \"best_model.pth\"\n","    \n","    # Move model to gpu if possible\n","    net = net.to(device)\n","\n","    for epoch in range(n_epochs):  # loop over the dataset multiple times\n","\n","        running_loss = 0.0\n","        print_every = n_minibatches // 10\n","        start_time = time.time()\n","        total_train_loss = 0\n","        \n","        for i, (inputs, labels) in enumerate(train_loader):\n","\n","            # Move tensors to correct device\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            # zero the parameter gradients\n","            optimizer.zero_grad()\n","\n","            # forward + backward + optimize\n","            outputs = net(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            # print statistics\n","            running_loss += loss.item()\n","            total_train_loss += loss.item()\n","\n","            # print every 10th of epoch\n","            if (i + 1) % (print_every + 1) == 0:    \n","                print(\"Epoch {}, {:d}% \\t train_loss: {:.2f} took: {:.2f}s\".format(\n","                      epoch + 1, int(100 * (i + 1) / n_minibatches), running_loss / print_every,\n","                      time.time() - start_time))\n","                running_loss = 0.0\n","                start_time = time.time()\n","\n","        train_history.append(total_train_loss / len(train_loader))\n","\n","        total_val_loss = 0\n","        # Do a pass on the validation set\n","        # We don't need to compute gradient,\n","        # we save memory and computation using th.no_grad()\n","        with torch.no_grad():\n","          for inputs, labels in val_loader:\n","              # Move tensors to correct device\n","              inputs, labels = inputs.to(device), labels.to(device)\n","              # Forward pass\n","              predictions = net(inputs)\n","              val_loss = criterion(predictions, labels)\n","              total_val_loss += val_loss.item()\n","            \n","        val_history.append(total_val_loss / len(val_loader))\n","        # Save model that performs best on validation set\n","        if total_val_loss \u003c best_error:\n","            best_error = total_val_loss\n","            torch.save(net.state_dict(), best_model_path)\n","\n","        print(\"Validation loss = {:.2f}\".format(total_val_loss / len(val_loader)))\n","\n","    print(\"Training Finished, took {:.2f}s\".format(time.time() - training_start_time))\n","    \n","    # Load best model\n","    net.load_state_dict(torch.load(best_model_path))\n","    \n","    return train_history, val_history"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"cJX2anB5cay_"},"outputs":[{"name":"stdout","output_type":"stream","text":["===== HYPERPARAMETERS =====\n","batch_size= 32\n","n_epochs= 10\n","learning_rate= 0.001\n","==============================\n","Epoch 1, 10% \t train_loss: 1.18 took: 12.78s\n","Epoch 1, 20% \t train_loss: 0.82 took: 4.74s\n","Epoch 1, 30% \t train_loss: 0.72 took: 4.66s\n","Epoch 1, 40% \t train_loss: 0.71 took: 4.61s\n","Epoch 1, 50% \t train_loss: 0.65 took: 4.71s\n","Epoch 1, 60% \t train_loss: 0.63 took: 4.67s\n","Epoch 1, 70% \t train_loss: 0.59 took: 4.71s\n","Epoch 1, 80% \t train_loss: 0.60 took: 4.75s\n","Epoch 1, 90% \t train_loss: 0.57 took: 4.59s\n","Validation loss = 0.54\n","Epoch 2, 10% \t train_loss: 0.54 took: 4.83s\n","Epoch 2, 20% \t train_loss: 0.53 took: 4.69s\n","Epoch 2, 30% \t train_loss: 0.52 took: 4.68s\n","Epoch 2, 40% \t train_loss: 0.57 took: 4.70s\n","Epoch 2, 50% \t train_loss: 0.52 took: 4.60s\n","Epoch 2, 60% \t train_loss: 0.52 took: 4.63s\n","Epoch 2, 70% \t train_loss: 0.50 took: 4.71s\n","Epoch 2, 80% \t train_loss: 0.50 took: 4.62s\n","Epoch 2, 90% \t train_loss: 0.48 took: 4.66s\n","Validation loss = 0.49\n","Epoch 3, 10% \t train_loss: 0.48 took: 4.80s\n","Epoch 3, 20% \t train_loss: 0.46 took: 4.59s\n","Epoch 3, 30% \t train_loss: 0.46 took: 4.67s\n","Epoch 3, 40% \t train_loss: 0.43 took: 4.60s\n","Epoch 3, 50% \t train_loss: 0.46 took: 4.48s\n","Epoch 3, 60% \t train_loss: 0.47 took: 5.28s\n","Epoch 3, 70% \t train_loss: 0.44 took: 4.46s\n","Epoch 3, 80% \t train_loss: 0.43 took: 4.54s\n","Epoch 3, 90% \t train_loss: 0.45 took: 4.44s\n","Validation loss = 0.42\n","Epoch 4, 10% \t train_loss: 0.42 took: 4.73s\n","Epoch 4, 20% \t train_loss: 0.45 took: 4.44s\n","Epoch 4, 30% \t train_loss: 0.41 took: 4.44s\n","Epoch 4, 40% \t train_loss: 0.41 took: 4.49s\n","Epoch 4, 50% \t train_loss: 0.41 took: 4.44s\n","Epoch 4, 60% \t train_loss: 0.41 took: 4.47s\n","Epoch 4, 70% \t train_loss: 0.40 took: 4.58s\n","Epoch 4, 80% \t train_loss: 0.40 took: 4.48s\n","Epoch 4, 90% \t train_loss: 0.42 took: 4.50s\n","Validation loss = 0.38\n","Epoch 5, 10% \t train_loss: 0.39 took: 4.65s\n","Epoch 5, 20% \t train_loss: 0.38 took: 4.45s\n","Epoch 5, 30% \t train_loss: 0.40 took: 4.50s\n","Epoch 5, 40% \t train_loss: 0.39 took: 4.55s\n","Epoch 5, 50% \t train_loss: 0.40 took: 4.48s\n","Epoch 5, 60% \t train_loss: 0.40 took: 4.48s\n","Epoch 5, 70% \t train_loss: 0.39 took: 4.46s\n","Epoch 5, 80% \t train_loss: 0.39 took: 4.56s\n","Epoch 5, 90% \t train_loss: 0.38 took: 4.49s\n","Validation loss = 0.37\n","Epoch 6, 10% \t train_loss: 0.37 took: 4.77s\n","Epoch 6, 20% \t train_loss: 0.37 took: 4.52s\n","Epoch 6, 30% \t train_loss: 0.35 took: 4.51s\n","Epoch 6, 40% \t train_loss: 0.38 took: 4.54s\n","Epoch 6, 50% \t train_loss: 0.37 took: 4.60s\n","Epoch 6, 60% \t train_loss: 0.37 took: 4.54s\n","Epoch 6, 70% \t train_loss: 0.36 took: 4.46s\n","Epoch 6, 80% \t train_loss: 0.38 took: 4.47s\n","Epoch 6, 90% \t train_loss: 0.34 took: 4.50s\n","Validation loss = 0.34\n","Epoch 7, 10% \t train_loss: 0.34 took: 4.81s\n","Epoch 7, 20% \t train_loss: 0.35 took: 4.64s\n","Epoch 7, 30% \t train_loss: 0.34 took: 4.60s\n","Epoch 7, 40% \t train_loss: 0.36 took: 4.63s\n","Epoch 7, 50% \t train_loss: 0.34 took: 4.65s\n","Epoch 7, 60% \t train_loss: 0.34 took: 4.62s\n","Epoch 7, 70% \t train_loss: 0.35 took: 4.59s\n","Epoch 7, 80% \t train_loss: 0.37 took: 4.62s\n","Epoch 7, 90% \t train_loss: 0.33 took: 5.33s\n","Validation loss = 0.33\n","Epoch 8, 10% \t train_loss: 0.34 took: 4.86s\n","Epoch 8, 20% \t train_loss: 0.34 took: 4.59s\n","Epoch 8, 30% \t train_loss: 0.33 took: 4.63s\n","Epoch 8, 40% \t train_loss: 0.35 took: 4.62s\n","Epoch 8, 50% \t train_loss: 0.33 took: 4.63s\n","Epoch 8, 60% \t train_loss: 0.32 took: 4.59s\n","Epoch 8, 70% \t train_loss: 0.35 took: 4.65s\n","Epoch 8, 80% \t train_loss: 0.33 took: 4.58s\n","Epoch 8, 90% \t train_loss: 0.32 took: 4.58s\n","Validation loss = 0.32\n","Epoch 9, 10% \t train_loss: 0.33 took: 4.87s\n","Epoch 9, 20% \t train_loss: 0.32 took: 4.58s\n","Epoch 9, 30% \t train_loss: 0.33 took: 4.65s\n","Epoch 9, 40% \t train_loss: 0.31 took: 4.59s\n","Epoch 9, 50% \t train_loss: 0.33 took: 4.65s\n","Epoch 9, 60% \t train_loss: 0.31 took: 4.66s\n","Epoch 9, 70% \t train_loss: 0.33 took: 4.68s\n","Epoch 9, 80% \t train_loss: 0.33 took: 4.62s\n","Epoch 9, 90% \t train_loss: 0.34 took: 4.63s\n","Validation loss = 0.32\n","Epoch 10, 10% \t train_loss: 0.29 took: 4.74s\n","Epoch 10, 20% \t train_loss: 0.31 took: 4.39s\n","Epoch 10, 30% \t train_loss: 0.31 took: 4.44s\n","Epoch 10, 40% \t train_loss: 0.30 took: 4.39s\n","Epoch 10, 50% \t train_loss: 0.34 took: 4.47s\n","Epoch 10, 60% \t train_loss: 0.33 took: 4.41s\n","Epoch 10, 70% \t train_loss: 0.31 took: 4.42s\n","Epoch 10, 80% \t train_loss: 0.34 took: 4.51s\n","Epoch 10, 90% \t train_loss: 0.33 took: 4.46s\n","Validation loss = 0.32\n","Training Finished, took 508.59s\n"]}],"source":["from torchvision.models.resnet import ResNet, BasicBlock\n","\n","class FMnistResNet(ResNet):\n","    def __init__(self):\n","        super(FMnistResNet, self).__init__(BasicBlock, [2, 2, 2, 2], num_classes=10)\n","        self.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","        \n","    def forward(self, x):\n","        return super(FMnistResNet, self).forward(x)\n","\n","net = FMnistResNet()\n","train_history, val_history = train(net, batch_size=32, n_epochs=10, learning_rate=0.001)"]},{"cell_type":"markdown","metadata":{"id":"UkVKNPtccazC"},"source":["Now, let's look at the evolution of the losses"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4CUQt-HJcazF"},"outputs":[],"source":["plot_losses(train_history, val_history)"]},{"cell_type":"markdown","metadata":{"id":"O90WcUTwt2GU"},"source":["### 5. Test the network on the test data\n","\n","\n","We have trained the network for 2 passes over the training dataset.\n","But we need to check if the network has learnt anything at all.\n","\n","We will check this by predicting the class label that the neural network\n","outputs, and checking it against the ground-truth. If the prediction is\n","correct, we add the sample to the list of correct predictions.\n","\n","Okay, first step. Let us display an image from the test set to get familiar.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V4vljwBlt2GX"},"outputs":[],"source":["try:\n","  images, labels = next(iter(test_loader))\n","except EOFError:\n","  pass\n","\n","# print images\n","imshow(torchvision.utils.make_grid(images))\n","print(\"Ground truth:\\n\")\n","\n","print(' '.join('{:\u003e10}'.format(classes[labels[j]]) for j in range(test_batch_size)))"]},{"cell_type":"markdown","metadata":{"id":"KpmaQT4Zt2Gn"},"source":["Okay, now let us see what the neural network thinks these examples above are:\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"utIfocFrt2Gs"},"outputs":[],"source":["outputs = net(images.to(device))\n","print(outputs.size())"]},{"cell_type":"markdown","metadata":{"id":"6mU42O0Gt2G2"},"source":["The outputs are energies for the 10 classes.\n","The higher the energy for a class, the more the network\n","thinks that the image is from that particular class.\n","So, let's get the index of the highest energy:\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IWTWHHs9t2G5"},"outputs":[],"source":["_, predicted = torch.max(outputs, 1)\n","\n","print(\"Predicted:\\n\")\n","imshow(torchvision.utils.make_grid(images))\n","\n","print(' '.join('{:\u003e10}'.format(classes[predicted[j]]) for j in range(test_batch_size)))"]},{"cell_type":"markdown","metadata":{"id":"AUpCEAOTt2HK"},"source":["The results seem pretty good.\n","\n","Let us look at how the network performs on the whole test set.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LI6JtYwTt2HM"},"outputs":[],"source":["def dataset_accuracy(net, data_loader, name=\"\"):\n","    net = net.to(device)\n","    correct = 0\n","    total = 0\n","    for images, labels in data_loader:\n","        images, labels = images.to(device), labels.to(device)\n","        outputs = net(images)\n","        _, predicted = torch.max(outputs, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum()\n","    accuracy = 100 * float(correct) / total\n","    print('Accuracy of the network on the {} {} images: {:.2f} %'.format(total, name, accuracy))\n","\n","def train_set_accuracy(net):\n","    dataset_accuracy(net, train_loader, \"train\")\n","\n","def val_set_accuracy(net):\n","    dataset_accuracy(net, val_loader, \"validation\")  \n","    \n","def test_set_accuracy(net):\n","    dataset_accuracy(net, test_loader, \"test\")\n","\n","def compute_accuracy(net):\n","    train_set_accuracy(net)\n","    val_set_accuracy(net)\n","    test_set_accuracy(net)\n","    \n","print(\"Computing accuracy...\")\n","compute_accuracy(net)"]},{"cell_type":"markdown","metadata":{"id":"iGGyra-4t2HW"},"source":["That initial 59.78 % on the test set of images looks waaay better than chance, which is 10% accuracy (randomly picking\n","a class out of 10 classes).\n","Seems like the network learnt something.\n","As a baseline, a linear model achieves around 30% accuracy.\n","\n","What are the classes that performed well, and the classes that did not perform well?\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rkim9_INt2HY"},"outputs":[],"source":["def accuracy_per_class(net):\n","    net = net.to(device)\n","    n_classes = 10\n","    # (real, predicted)\n","    confusion_matrix = np.zeros((n_classes, n_classes), dtype=np.int64)\n","\n","    for images, labels in test_loader:\n","        images, labels = images, labels = images.to(device), labels.to(device)\n","        outputs = net(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        for i in range(test_batch_size):\n","            confusion_matrix[labels[i], predicted[i]] += 1\n","            label = labels[i]\n","\n","    print(\"{:\u003c10} {:^10}\".format(\"Class\", \"Accuracy (%)\"))\n","    for i in range(n_classes):\n","        class_total = confusion_matrix[i, :].sum()\n","        class_correct = confusion_matrix[i, i]\n","        percentage_correct = 100.0 * float(class_correct) / class_total\n","        \n","        print('{:\u003c10} {:^10.2f}'.format(classes[i], percentage_correct))\n","    return confusion_matrix\n","\n","confusion_matrix = accuracy_per_class(net)"]},{"cell_type":"markdown","metadata":{"id":"AZKLymOacazg"},"source":["### Confusion Matrix"]},{"cell_type":"markdown","metadata":{"id":"ekJHz3vpcazg"},"source":["Let's look at what type of error our networks makes... \n","It seems that our network is pretty good at classifying ships,\n","but has some difficulties to differentiate cats and dogs.\n","Also, it classifies a lot of trucks as cars."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1aYMqD1Ocazi"},"outputs":[],"source":["# Plot normalized confusion matrix\n","plot_confusion_matrix(confusion_matrix, classes, normalize=True,\n","                      title='Normalized confusion matrix')\n","\n","# Plot non-normalized confusion matrix\n","plot_confusion_matrix(confusion_matrix, classes,\n","                      title='Confusion matrix, without normalization')"]}],"metadata":{"accelerator":"GPU","colab":{"name":"","provenance":[{"file_id":"1B5KQvPySqYEa6XicRHdOwgv8fN1BrCgQ","timestamp":1576556302985},{"file_id":"1hGEWSrQHJUtZxvXm1Lz_5o6r-9gCr2Uc","timestamp":1541510858242}],"version":""},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}