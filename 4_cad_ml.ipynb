{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lxoOSt7SO0mB"
   },
   "source": [
    "# Machine Learning with CAD Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_CBkRGPlO0mE"
   },
   "source": [
    "Download the ABC dataset from https://deep-geometry.github.io/abc-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: meta_v00.txt: No such file or directory\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0curl: (6) Could not resolve host: sh\n"
     ]
    }
   ],
   "source": [
    "!cat meta_v00.txt | xargs -n 2 -P 8 sh -c 'curl --insecure -o meta/$1 $0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uRg3dLR6O0mF"
   },
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 404,
     "status": "ok",
     "timestamp": 1615079504888,
     "user": {
      "displayName": "Aditya Balu",
      "photoUrl": "",
      "userId": "00240964590008989444"
     },
     "user_tz": 300
    },
    "id": "E3vVqAkJO4wt",
    "outputId": "7ead7811-b042-4bab-ee79-352124d04af7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - conda-forge/label/cf202003\n",
      " - defaults\n",
      "Platform: linux-64\n",
      "doneecting package metadata (repodata.json): ...working... \n",
      "doneing environment: ...working... \n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! conda install -c conda-forge/label/cf202003 meshplot -y -qqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 387
    },
    "executionInfo": {
     "elapsed": 392,
     "status": "error",
     "timestamp": 1615079370938,
     "user": {
      "displayName": "Aditya Balu",
      "photoUrl": "",
      "userId": "00240964590008989444"
     },
     "user_tz": 300
    },
    "id": "Q_AvbqdEO0mG",
    "outputId": "6e231483-131a-4da1-9f35-8ca61079f90b"
   },
   "outputs": [],
   "source": [
    "import meshplot as mp \n",
    "import numpy as np\n",
    "import igl\n",
    "import yaml\n",
    "from yaml import CLoader as Loader\n",
    "\n",
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kZ9H6urUO0mG"
   },
   "source": [
    "## Reading CAD Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2OeT6n16O0mH",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_model(obj_path, feat_path):\n",
    "    v, _, n, f, _, ni = igl.read_obj(obj_path)\n",
    "            \n",
    "    with open(feat_path) as fi:\n",
    "        feat = yaml.load(fi, Loader=Loader)\n",
    "    m = {\"vertices\": v, \"face_indices\": f, \"normals\": n, \n",
    "        \"normal_indices\": ni, \"features\": feat}\n",
    "    return m\n",
    "\n",
    "m = read_model(\"data/test_trimesh.obj\", \"data/test_features.yml\")\n",
    "v, f, feat ,= m[\"vertices\"], m[\"face_indices\"], m[\"features\"]\n",
    "print(v.shape, f.shape)\n",
    "print(list(feat.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qRJrTDcoO0mI"
   },
   "source": [
    "## CAD Features: Surface Normals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GHUfzy7wO0mI"
   },
   "outputs": [],
   "source": [
    "from data.utils import get_averaged_normals\n",
    "\n",
    "# Average normals at vertices with multiple normals\n",
    "av_normals = get_averaged_normals(m)\n",
    "\n",
    "p = mp.plot(v, f, c=np.abs(av_normals), return_plot=True)\n",
    "\n",
    "# Add normals to the plot\n",
    "p.add_lines(v, v + av_normals, shading={\"line_color\": \"black\"});\n",
    "\n",
    "# Determine normals with uniform weighting in libigl\n",
    "normals = igl.per_vertex_normals(v, f)\n",
    "p.add_lines(v, v + normals, shading={\"line_color\": \"red\"});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jy0KAxLOO0mJ"
   },
   "source": [
    "## CAD Features: Sharp Edges/Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gMYa0efiO0mJ"
   },
   "outputs": [],
   "source": [
    "# Retrieve the sharp features\n",
    "lines = []\n",
    "for i, fe in enumerate(feat[\"curves\"]):\n",
    "    if fe[\"sharp\"]:\n",
    "        for j in range(len(fe[\"vert_indices\"])-1):\n",
    "            lines.append([fe[\"vert_indices\"][j], fe[\"vert_indices\"][j+1]])\n",
    "# Visualize the sharp features            \n",
    "p = mp.plot(v, f)\n",
    "p.add_edges(v, np.array(lines));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J0jbgktKO0mK"
   },
   "source": [
    "## CAD Features: Sharp Edges/Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cvUfn-ORO0mK"
   },
   "outputs": [],
   "source": [
    "# Retrieve the sharp features\n",
    "v_class = np.zeros((v.shape[0], 1))\n",
    "for i, fe in enumerate(feat[\"curves\"]):\n",
    "    if fe[\"sharp\"]:\n",
    "        v_class[fe[\"vert_indices\"]] = 1\n",
    "        \n",
    "# Visualize the sharp features            \n",
    "mp.plot(v, c=-v_class, shading={\"point_size\": 4.});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NahaIAHKO0mL"
   },
   "source": [
    "## CAD Features: Surface Patch Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QvSPRH-DO0mL"
   },
   "outputs": [],
   "source": [
    "# Retrieve the surface patch types\n",
    "t_map = {\"Plane\": 0, \"Cylinder\": 1,\n",
    "         \"Cone\": 2, \"Sphere\": 3,\n",
    "         \"Torus\": 4, \"Bezier\": 5,\n",
    "         \"BSpline\": 6, \"Revolution\": 7,\n",
    "         \"Extrusion\": 8, \"Other\": 9}\n",
    "\n",
    "c1 = np.zeros(f.shape[0])\n",
    "for fe in feat[\"surfaces\"]:\n",
    "    t = t_map[fe[\"type\"]]\n",
    "    for j in fe[\"face_indices\"]:\n",
    "        c1[j] = t\n",
    "\n",
    "# Visualize the patch types\n",
    "mp.plot(v, f, -c1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vtPknxCNO0mM"
   },
   "source": [
    "## CAD Features: Surface Patch Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pl-hnzeyO0mN"
   },
   "outputs": [],
   "source": [
    "# Retrieve the surface patch types per vertex\n",
    "c2 = np.zeros(v.shape[0])\n",
    "for fe in feat[\"surfaces\"]:\n",
    "    t = t_map[fe[\"type\"]]\n",
    "    for j in fe[\"vert_indices\"]:\n",
    "        c2[j] = t\n",
    "\n",
    "# Visualize the vertices\n",
    "mp.plot(v, c=-c2, shading={\"point_size\": 4.});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IX1UoS9LO0mN"
   },
   "source": [
    "## Machine Learning Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zpeexc_CO0mO"
   },
   "source": [
    "## Installation\n",
    "\n",
    "We use [Pytorch](https://pytorch.org/) and [Pytorch Geometric](https://pytorch-geometric.readthedocs.io/en/latest/) that can be installed as described in their documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5wiHNneBO0mP"
   },
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch-geometric -qqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "3TT706eyO0mP"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'data.utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DynamicEdgeConv\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MLP\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ABCDataset\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'data.utils'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Sequential, Dropout, Linear\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.nn import DynamicEdgeConv\n",
    "\n",
    "from data.utils import MLP\n",
    "from data.utils import ABCDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FQRor6ufO0mQ"
   },
   "source": [
    "## Loading the CAD Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ts8ZRDWVO0mR"
   },
   "outputs": [],
   "source": [
    "tf_train = T.Compose([\n",
    "    T.FixedPoints(5000, replace=False),\n",
    "    T.RandomTranslate(0.002),\n",
    "    T.RandomRotate(15, axis=0),\n",
    "    T.RandomRotate(15, axis=1),\n",
    "    T.RandomRotate(15, axis=2)\n",
    "])\n",
    "tf_test = T.Compose([T.FixedPoints(10000, replace=False)])\n",
    "pre = T.NormalizeScale()\n",
    "\n",
    "train_dataset_n = ABCDataset(\"data/ml/ABC\", \"Normals\", True, tf_train, pre)\n",
    "test_dataset_n = ABCDataset(\"data/ml/ABC\", \"Normals\", False, tf_test, pre)\n",
    "train_dataset_e = ABCDataset(\"data/ml/ABC\", \"Edges\", True, tf_train, pre)\n",
    "test_dataset_e = ABCDataset(\"data/ml/ABC\", \"Edges\", False, tf_test, pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VPwz0DTzO0mS"
   },
   "source": [
    " ## Statistics and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3kECX2mCO0mS"
   },
   "outputs": [],
   "source": [
    "dataset = test_dataset_e\n",
    "print(\"Number of models:\", len(dataset))\n",
    "print(\"Number of classes:\", dataset.num_classes)\n",
    "\n",
    "counts = [0]*dataset.num_classes\n",
    "total = 0\n",
    "for d in dataset:\n",
    "    y = d.y.numpy()\n",
    "    for i in range(dataset.num_classes):\n",
    "        counts[i] += np.sum(y==i)\n",
    "    total += y.shape[0]\n",
    "\n",
    "for i, c in enumerate(counts):\n",
    "    print(\"%0.2f%% labels are of class %i.\"%(c/total, i))\n",
    "    \n",
    "d = test_dataset_e[3]\n",
    "v = d.pos.numpy()\n",
    "y = d.y.numpy()\n",
    "print(\"Shape of model:\", v.shape)\n",
    "print(\"Shape of labels:\", y.shape)\n",
    "mp.plot(v, c=-y, shading={\"point_size\": 0.15});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GDUYVGEeO0mS"
   },
   "outputs": [],
   "source": [
    "d = test_dataset_n[4]\n",
    "v = d.pos.numpy()\n",
    "y = d.y.numpy()\n",
    "mp.plot(v, c=np.abs(y), shading={\"point_size\": 0.15});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "52Qk0acoO0mT"
   },
   "source": [
    "## Defining the Network (DGCNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kAGYp09BO0mT"
   },
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, out_channels, k=30, aggr='max', \n",
    "                 typ='Edges'):\n",
    "        super(Net, self).__init__()\n",
    "        self.typ = typ\n",
    "        self.conv1 = DynamicEdgeConv(MLP([2 * 3, 64, 64]), k, aggr)\n",
    "        self.conv2 = DynamicEdgeConv(MLP([2* 64, 64, 64]), k, aggr)\n",
    "        self.conv3 = DynamicEdgeConv(MLP([2* 64, 64, 64]), k, aggr)\n",
    "        self.lin1 = MLP([3 * 64, 1024])\n",
    "\n",
    "        self.mlp = Sequential(MLP([1024, 256]), Dropout(0.5), \n",
    "                              MLP([256, 128]), Dropout(0.5), \n",
    "                              Linear(128, out_channels))\n",
    "\n",
    "    def forward(self, data):\n",
    "        pos, batch = data.pos, data.batch\n",
    "        x1 = self.conv1(pos, batch)\n",
    "        x2 = self.conv2(x1, batch)\n",
    "        x3 = self.conv3(x2, batch)\n",
    "        out = self.lin1(torch.cat([x1, x2, x3], dim=1))\n",
    "        out = self.mlp(out)\n",
    "        if self.typ == \"Edges\" or self.typ == \"Types\":\n",
    "            return F.log_softmax(out, dim=1)\n",
    "        if self.typ == \"Normals\":\n",
    "            return F.normalize(out, p=2, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7MX8MR2WO0mU"
   },
   "source": [
    "## Visualizing the Nearest Neighbour Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Dol4ov2O0mV"
   },
   "outputs": [],
   "source": [
    "tf_pre = T.Compose([\n",
    "    T.FixedPoints(1000),\n",
    "    T.NormalizeScale(),\n",
    "    T.KNNGraph(k=6)\n",
    "])\n",
    "\n",
    "dataset = ABCDataset(\"data/ml/ABC_graph\", \"Edges\", pre_transform=tf_pre)\n",
    "vd = dataset[0].pos.numpy()\n",
    "p = mp.plot(vd, shading={\"point_size\": 0.15})\n",
    "p.add_edges(vd, dataset[0].edge_index.numpy().T);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mntG8j98O0mV"
   },
   "source": [
    "## Defining the Loss Function (Normals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9oX-WQ3uO0mW"
   },
   "outputs": [],
   "source": [
    "class Cosine_Loss(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Cosine_Loss,self).__init__()\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        dotp = torch.mul(x, y).sum(1)\n",
    "        loss = torch.sum(1 - dotp.pow(2)) / x.shape[0]\n",
    "        angle = torch.sum(torch.acos(\n",
    "                torch.clamp(torch.abs(dotp), 0.0, 1.0))) / x.shape[0]\n",
    "        return loss, angle\n",
    "\n",
    "cosine_loss = Cosine_Loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lH1veYzgO0mW"
   },
   "source": [
    "## Defining the Training Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D4UjX3ZQO0mW"
   },
   "outputs": [],
   "source": [
    "def train(loader, typ=\"Edges\"):\n",
    "    model.train()\n",
    "\n",
    "    for i, data in enumerate(loader):\n",
    "        total_loss = correct_nodes = total_nodes = 0\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        \n",
    "        if typ == \"Edges\" or typ == \"Types\":\n",
    "            loss = F.nll_loss(out, data.y)\n",
    "        if typ == \"Normals\":\n",
    "            loss, angle = cosine_loss(out, data.y)\n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if typ == \"Edges\" or typ == \"Types\":\n",
    "            pred = out.max(dim=1)[1]\n",
    "            correct_nodes += pred.eq(data.y).sum().item()\n",
    "            total_nodes += data.num_nodes\n",
    "            acc = correct_nodes / total_nodes\n",
    "            \n",
    "        if typ == \"Normals\":\n",
    "            acc = angle.item()*180/np.pi\n",
    "        \n",
    "        print('[Train {}/{}] Loss: {:.4f}, Accuracy: {:.4f}'.format(\n",
    "              i + 1, len(loader), total_loss / loader.batch_size, acc)),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OAeVruUnO0mX"
   },
   "source": [
    "## Defining the Testing Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rPtDvNCIO0mX",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def test(loader, typ=\"Edges\"):\n",
    "    model.eval()\n",
    "\n",
    "    correct_nodes = total_nodes = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        with torch.no_grad():\n",
    "            out = model(data)\n",
    "            \n",
    "        if typ == \"Edges\" or typ == \"Types\":\n",
    "            pred = out.max(dim=1)[1]\n",
    "            correct_nodes += pred.eq(data.y).sum().item()\n",
    "            total_nodes += data.num_nodes\n",
    "            \n",
    "        if typ == \"Normals\":\n",
    "            _, angle = cosine_loss(out, data.y)\n",
    "            correct_nodes += angle.item() * 180 / np.pi\n",
    "            total_nodes += 1\n",
    "            \n",
    "    return correct_nodes / total_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E6Y51IRdO0mY"
   },
   "source": [
    "## Running the Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PmnESSfzO0mZ"
   },
   "outputs": [],
   "source": [
    "typ = \"Edges\"\n",
    "\n",
    "if typ == \"Edges\":\n",
    "    train_dataset = train_dataset_e\n",
    "    test_dataset = test_dataset_e\n",
    "\n",
    "if typ == \"Normals\":\n",
    "    train_dataset = train_dataset_n\n",
    "    test_dataset = test_dataset_n\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net(train_dataset.num_classes, k=30, typ=typ).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, \n",
    "                                            step_size=20, gamma=0.8)\n",
    "\n",
    "for epoch in range(1, 3):\n",
    "    train(train_loader, typ=typ)\n",
    "    acc = test(test_loader, typ=typ)\n",
    "    print('Test: {:02d}, Accuracy: {:.4f}'.format(epoch, acc))\n",
    "    torch.save(model.state_dict(), \"%02i_%.2f.dat\"%(epoch, acc))\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tT3tZCxIO0mZ"
   },
   "source": [
    "## Loading a Pretrained Model - Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z_eGG797O0mZ"
   },
   "outputs": [],
   "source": [
    "typ = \"Edges\"\n",
    "test_dataset = test_dataset_e\n",
    "state_file = \"Edges_72_0.96.dat\"\n",
    "\n",
    "model = Net(test_dataset.num_classes, k=30, typ=typ)\n",
    "if torch.cuda.is_available():\n",
    "    state = torch.load(\"data/ml/ABC/models/%s\"%state_file)\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    state = torch.load(\"data/ml/ABC/models/%s\"%state_file, \n",
    "                       map_location=torch.device('cpu'))\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "model.load_state_dict(state)\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MIn53b9XO0ma"
   },
   "source": [
    "## Visualizing the Predicted Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uhp0vYsUO0ma"
   },
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "loader = iter(test_loader)\n",
    "\n",
    "d = loader.next()\n",
    "with torch.no_grad():\n",
    "    out = model(d.to(device))\n",
    "\n",
    "v = d.pos.cpu().numpy()\n",
    "y = d.y.cpu().numpy()\n",
    "\n",
    "# Calculate accuracy \n",
    "acc = test(test_loader, typ=typ)\n",
    "print('Accuracy: {:.4f}'.format(acc))\n",
    "\n",
    "# Plot groundtruth left, estimation right\n",
    "e = out.max(dim=1)[1].cpu().numpy()\n",
    "p = mp.subplot(v, c=-y, s=[1, 2, 0], shading={\"point_size\":0.15})\n",
    "mp.subplot(v, c=-e, s=[1, 2, 1], data=p, shading={\"point_size\": 0.15});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f7_cjftLO0mc"
   },
   "source": [
    "## Loading a Pretrained Model - Normals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lhYgsLn6O0mf"
   },
   "outputs": [],
   "source": [
    "typ = \"Normals\"\n",
    "test_dataset = test_dataset_n\n",
    "state_file = \"Normals_44_12.52.dat\"\n",
    "\n",
    "model = Net(test_dataset.num_classes, k=30, typ=typ)\n",
    "if torch.cuda.is_available():\n",
    "    state = torch.load(\"data/ml/ABC/models/%s\"%state_file)\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    state = torch.load(\"data/ml/ABC/models/%s\"%state_file, \n",
    "                       map_location=torch.device('cpu'))\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "model.load_state_dict(state)\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oo2lNKFJO0mg"
   },
   "source": [
    "## Visualizing the Predicted Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0CIcie0SO0mh"
   },
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "loader = iter(test_loader)\n",
    "\n",
    "d = loader.next()\n",
    "with torch.no_grad():\n",
    "    out = model(d.to(device))\n",
    "\n",
    "v = d.pos.cpu().numpy()\n",
    "y = d.y.cpu().numpy()\n",
    "\n",
    "# Calculate accuracy\n",
    "_, angle = cosine_loss(out, d.y)\n",
    "print(angle.item() * 180 / np.pi)\n",
    "\n",
    "# Plot groundtruth left, estimation right\n",
    "n = out.cpu().numpy()\n",
    "c1 = np.abs(y)\n",
    "c2 = np.abs(n)\n",
    "p = mp.subplot(v, c=c1, s=[1, 2, 0], shading={\"point_size\":0.15})\n",
    "mp.subplot(v, c=c2, s=[1, 2, 1], data=p, shading={\"point_size\": 0.15})"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "cad_ml.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "rise": {
   "center": false,
   "progress": false,
   "scroll": true,
   "slidenumber": false,
   "theme": "while",
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
